{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSE Unified Multi-Company LSTM Predictor\n",
    "\n",
    "This notebook trains a **single, unified LSTM model** to predict future stock prices for all companies in a dataset. Instead of training one model per company, this approach allows the model to learn general market patterns from all available data, which can lead to better generalization and performance.\n",
    "\n",
    "### Key Changes from the Per-Scrip Approach:\n",
    "\n",
    "1.  **Global Scaler**: A single `MinMaxScaler` is fit on the training data of **all companies**. This ensures that data from different stocks (with varying price ranges) is normalized consistently.\n",
    "2.  **Company Embeddings**: To distinguish between companies, each `Scrip` is assigned a unique integer ID. An `Embedding` layer in the model learns a unique vector representation for each company, capturing its specific characteristics.\n",
    "3.  **Multi-Input Model**: The Keras Functional API is used to build a model that accepts two inputs:\n",
    "    - The time-series data (e.g., 60 days of OHLCV).\n",
    "    - The integer ID of the company (`Scrip`).\n",
    "4.  **Centralized Artifacts**: Only one model file and one scaler file are saved for each forecast horizon (e.g., 1, 3, 7 days)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Imports & Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 12:29:16.406384: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from typing import Tuple, Dict, Any, List\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Reproducibility\n",
    "def set_global_seed(seed: int = 42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_global_seed(42)\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts will be saved to: /mnt/Work/projects/stock_cast/predictor/artifacts_unified\n"
     ]
    }
   ],
   "source": [
    "# === Required: set your CSV path here ===\n",
    "CSV_PATH = \"./dataset/merged_stock_data.csv\"  # <- CHANGE THIS to your dataset path\n",
    "\n",
    "# === Columns ===\n",
    "DATE_COLUMN = \"Date\"\n",
    "SCRIP_COLUMN = \"Scrip\"\n",
    "TARGET_COLUMN = \"Close\"   # The column we want to predict\n",
    "\n",
    "# === Features ===\n",
    "# Using multivariate features is highly recommended for a unified model.\n",
    "# The first feature should be the one you want to predict (TARGET_COLUMN).\n",
    "FEATURE_COLS = [\"Close\", \"Open\", \"High\", \"Low\", \"Volume\"]\n",
    "\n",
    "# === Sequence & Horizons ===\n",
    "SEQ_LEN = 60\n",
    "HORIZONS = [1, 3, 7] # Train a model for each forecast horizon\n",
    "\n",
    "# === Data Splits ===\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1 # 10% for validation, 10% for testing\n",
    "\n",
    "# === Training Hyperparameters ===\n",
    "MAX_EPOCHS = 50 # Reduced epochs as the dataset is much larger\n",
    "BATCH_SIZE = 256 # Increased batch size for larger dataset\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 5  # Early stopping patience\n",
    "\n",
    "# === Save Locations ===\n",
    "SAVE_DIR = \"./artifacts_unified\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Artifacts will be saved to:\", os.path.abspath(SAVE_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data Loading & Preparation\n",
    "\n",
    "This is the most modified section. We now perform the following steps:\n",
    "1.  Load all data and create a mapping from `Scrip` names to integer IDs.\n",
    "2.  Split the entire dataset by date into train, validation, and test sets.\n",
    "3.  Fit a **single, global `MinMaxScaler`** on the `FEATURE_COLS` of the **training set only**.\n",
    "4.  Group the data by `Scrip` and build sequences for each company separately to avoid creating windows that span across different stocks.\n",
    "5.  Concatenate all sequences into final `X` (features), `X_scrip` (company IDs), and `y` (targets) arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for 464 companies.\n",
      "Training set size: 1105256\n",
      "Validation set size: 138157\n",
      "Test set size: 138158\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(csv_path: str) -> Tuple[pd.DataFrame, Dict[str, int]]:\n",
    "    \"\"\"Loads data, sorts it, and creates a scrip-to-ID mapping.\"\"\"\n",
    "    df = pd.read_csv(csv_path, parse_dates=[DATE_COLUMN])\n",
    "    df = df.sort_values([SCRIP_COLUMN, DATE_COLUMN]).reset_index(drop=True)\n",
    "    df = df.dropna(subset=FEATURE_COLS)\n",
    "\n",
    "    # Create Scrip to Integer ID mapping\n",
    "    scrips = df[SCRIP_COLUMN].unique()\n",
    "    scrip_to_id = {scrip: i for i, scrip in enumerate(scrips)}\n",
    "    df['ScripID'] = df[SCRIP_COLUMN].map(scrip_to_id)\n",
    "\n",
    "    return df, scrip_to_id\n",
    "\n",
    "def build_all_sequences(df: pd.DataFrame, scrip_col: str, feature_cols: List[str], seq_len: int, n_ahead: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Builds sequences for all scrips and concatenates them.\"\"\"\n",
    "    all_X, all_X_scrip, all_y = [], [], []\n",
    "\n",
    "    # Group by scrip and build sequences for each one\n",
    "    for scrip_id, group in df.groupby('ScripID'):\n",
    "        values = group[feature_cols].values\n",
    "        T = len(values)\n",
    "\n",
    "        if T < seq_len + n_ahead:\n",
    "            continue # Skip scrips with not enough data\n",
    "\n",
    "        for i in range(T - seq_len - n_ahead + 1):\n",
    "            window = values[i : i + seq_len]\n",
    "            target = values[i + seq_len : i + seq_len + n_ahead, 0] # Target is the first feature_col (Close)\n",
    "\n",
    "            all_X.append(window)\n",
    "            all_y.append(target)\n",
    "            all_X_scrip.append(scrip_id)\n",
    "\n",
    "    return np.array(all_X), np.array(all_X_scrip), np.array(all_y)\n",
    "\n",
    "# --- Main Data Preparation Flow ---\n",
    "df_all, scrip_to_id = load_and_preprocess_data(CSV_PATH)\n",
    "n_scrips = len(scrip_to_id)\n",
    "print(f\"Loaded data for {n_scrips} companies.\")\n",
    "\n",
    "# Split data chronologically\n",
    "n = len(df_all)\n",
    "train_end = int(n * TRAIN_RATIO)\n",
    "val_end = int(n * (TRAIN_RATIO + VAL_RATIO))\n",
    "\n",
    "df_train = df_all.iloc[:train_end]\n",
    "df_val = df_all.iloc[train_end:val_end]\n",
    "df_test = df_all.iloc[val_end:]\n",
    "\n",
    "# Fit ONE scaler on the training data only\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(df_train[FEATURE_COLS])\n",
    "\n",
    "# Scale all datasets\n",
    "df_train.loc[:, FEATURE_COLS] = scaler.transform(df_train[FEATURE_COLS])\n",
    "df_val.loc[:, FEATURE_COLS] = scaler.transform(df_val[FEATURE_COLS])\n",
    "df_test.loc[:, FEATURE_COLS] = scaler.transform(df_test[FEATURE_COLS])\n",
    "\n",
    "print(f\"Training set size: {len(df_train)}\")\n",
    "print(f\"Validation set size: {len(df_val)}\")\n",
    "print(f\"Test set size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Unified Model Builder\n",
    "\n",
    "We use the Keras Functional API to create a model with two input branches:\n",
    "1.  **Time Series Input**: A standard LSTM path to process the sequence of price/volume data.\n",
    "2.  **Scrip ID Input**: An `Embedding` layer that learns a dense vector for each company. This vector acts as a unique 'signature' for the stock.\n",
    "\n",
    "These two paths are then concatenated before making the final prediction, allowing the model to combine general market patterns (from the LSTM) with company-specific characteristics (from the Embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unified_model(seq_len: int, n_features: int, n_scrips: int, n_ahead: int, lr: float = LEARNING_RATE) -> keras.Model:\n",
    "    \"\"\"Builds a multi-input Keras model with LSTM and Embedding layers.\"\"\"\n",
    "    # Input for time-series data\n",
    "    ts_input = layers.Input(shape=(seq_len, n_features), name='ts_input')\n",
    "\n",
    "    # Input for the scrip ID\n",
    "    scrip_input = layers.Input(shape=(1,), name='scrip_input')\n",
    "\n",
    "    # --- Branch 1: LSTM for time-series processing ---\n",
    "    x1 = layers.LSTM(128, return_sequences=True)(ts_input)\n",
    "    x1 = layers.Dropout(0.3)(x1)\n",
    "    x1 = layers.LSTM(64)(x1)\n",
    "    x1 = layers.Dropout(0.3)(x1)\n",
    "\n",
    "    # --- Branch 2: Embedding for scrip identity ---\n",
    "    # Embedding dimension can be tuned. A common heuristic is sqrt(n_scrips).\n",
    "    embedding_dim = int(np.sqrt(n_scrips))\n",
    "    x2 = layers.Embedding(input_dim=n_scrips, output_dim=embedding_dim, name='embedding')(scrip_input)\n",
    "    x2 = layers.Flatten()(x2) # Flatten the embedding output\n",
    "\n",
    "    # --- Concatenate branches ---\n",
    "    concatenated = layers.concatenate([x1, x2], name='concatenation')\n",
    "\n",
    "    # --- Output layer ---\n",
    "    output = layers.Dense(64, activation='relu')(concatenated)\n",
    "    output = layers.Dense(n_ahead, name='output')(output)\n",
    "\n",
    "    # --- Build and compile model ---\n",
    "    model = keras.Model(inputs=[ts_input, scrip_input], outputs=output)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_callbacks():\n",
    "    es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=1)\n",
    "    rlrop = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=max(2, PATIENCE//2), min_lr=1e-6, verbose=1)\n",
    "    return [es, rlrop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Training & Evaluation Loop\n",
    "\n",
    "The main loop now iterates through the `HORIZONS` (1, 3, 7 days). For each horizon:\n",
    "1.  Builds the sequences for all datasets (train, val, test).\n",
    "2.  Builds and trains the unified model.\n",
    "3.  Saves the trained model, the global scaler, and the scrip-to-ID mapping.\n",
    "4.  Evaluates the final model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training model for N_AHEAD = 1\n",
      "==================================================\n",
      "\n",
      "Building sequences...\n",
      "Train sequences: 1085381, Val sequences: 135155, Test sequences: 135195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 12:33:33.348843: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ ts_input            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">68,608</span> │ ts_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ scrip_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,744</span> │ scrip_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenation       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,504</span> │ concatenation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ ts_input            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m5\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m68,608\u001b[0m │ ts_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ scrip_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m49,408\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m21\u001b[0m)     │      \u001b[38;5;34m9,744\u001b[0m │ scrip_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenation       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m5,504\u001b[0m │ concatenation[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,329</span> (520.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m133,329\u001b[0m (520.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,329</span> (520.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,329\u001b[0m (520.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "Epoch 1/50\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 82ms/step - loss: 2.8961e-07 - mae: 2.3552e-04 - val_loss: 5.2772e-06 - val_mae: 0.0018 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 85ms/step - loss: 3.1455e-08 - mae: 1.2587e-04 - val_loss: 1.2946e-06 - val_mae: 8.8843e-04 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 1.5761e-08 - mae: 8.6692e-05\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 85ms/step - loss: 1.4221e-08 - mae: 8.1024e-05 - val_loss: 3.3651e-07 - val_mae: 4.5568e-04 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 85ms/step - loss: 5.0254e-09 - mae: 3.7283e-05 - val_loss: 3.4457e-07 - val_mae: 4.5857e-04 - learning_rate: 2.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 4.7658e-09 - mae: 3.7319e-05\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 85ms/step - loss: 4.8222e-09 - mae: 3.7338e-05 - val_loss: 3.3787e-07 - val_mae: 4.5665e-04 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 86ms/step - loss: 3.8984e-09 - mae: 2.8429e-05 - val_loss: 3.4082e-07 - val_mae: 4.6135e-04 - learning_rate: 4.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 3.7139e-09 - mae: 2.8292e-05\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 86ms/step - loss: 3.7761e-09 - mae: 2.8229e-05 - val_loss: 3.5595e-07 - val_mae: 4.6980e-04 - learning_rate: 4.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m4240/4240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 87ms/step - loss: 3.5870e-09 - mae: 2.5907e-05 - val_loss: 3.5512e-07 - val_mae: 4.6983e-04 - learning_rate: 8.0000e-06\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Evaluating on test data...\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9ms/step\n",
      "\n",
      "--- Test Metrics for N_AHEAD = 1 ---\n",
      "Mean RMSE across horizon: 593.3535\n",
      "Mean MAPE across horizon: 2891.4599%\n",
      "RMSE per step: [593.3535]\n",
      "MAPE per step: [np.float64(2891.4599)]\n",
      "\n",
      "Saving artifacts...\n",
      "Model saved to: ./artifacts_unified/unified_lstm_nahead1.keras\n",
      "Scaler saved to: ./artifacts_unified/global_scaler.bin\n",
      "Scrip map saved to: ./artifacts_unified/scrip_to_id.json\n",
      "\n",
      "==================================================\n",
      "Training model for N_AHEAD = 3\n",
      "==================================================\n",
      "\n",
      "Building sequences...\n",
      "Train sequences: 1084721, Val sequences: 135055, Test sequences: 135103\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ ts_input            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">68,608</span> │ ts_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ scrip_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,744</span> │ scrip_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenation       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,504</span> │ concatenation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ ts_input            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m5\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m68,608\u001b[0m │ ts_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ scrip_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m49,408\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m21\u001b[0m)     │      \u001b[38;5;34m9,744\u001b[0m │ scrip_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenation       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m5,504\u001b[0m │ concatenation[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,459</span> (521.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m133,459\u001b[0m (521.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,459</span> (521.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,459\u001b[0m (521.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "Epoch 1/50\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 88ms/step - loss: 4.0926e-07 - mae: 1.7893e-04 - val_loss: 2.0817e-05 - val_mae: 0.0036 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 88ms/step - loss: 3.7033e-08 - mae: 1.3208e-04 - val_loss: 8.0957e-06 - val_mae: 0.0023 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m4237/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2.4364e-08 - mae: 1.0757e-04\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 87ms/step - loss: 2.1590e-08 - mae: 1.0050e-04 - val_loss: 3.6789e-06 - val_mae: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 88ms/step - loss: 7.6703e-09 - mae: 4.5806e-05 - val_loss: 3.6919e-06 - val_mae: 0.0015 - learning_rate: 2.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m4237/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 7.8930e-09 - mae: 4.8353e-05\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 88ms/step - loss: 7.7597e-09 - mae: 4.7974e-05 - val_loss: 3.6580e-06 - val_mae: 0.0015 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 88ms/step - loss: 6.2826e-09 - mae: 3.6583e-05 - val_loss: 3.6294e-06 - val_mae: 0.0015 - learning_rate: 4.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m4237/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 6.3323e-09 - mae: 3.7059e-05\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 91ms/step - loss: 6.2579e-09 - mae: 3.6995e-05 - val_loss: 3.6356e-06 - val_mae: 0.0015 - learning_rate: 4.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 90ms/step - loss: 6.0043e-09 - mae: 3.3320e-05 - val_loss: 3.6319e-06 - val_mae: 0.0015 - learning_rate: 8.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m4237/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 6.0797e-09 - mae: 3.3533e-05\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 89ms/step - loss: 6.0525e-09 - mae: 3.3459e-05 - val_loss: 3.6277e-06 - val_mae: 0.0015 - learning_rate: 8.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 88ms/step - loss: 5.8974e-09 - mae: 3.2390e-05 - val_loss: 3.6327e-06 - val_mae: 0.0015 - learning_rate: 1.6000e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m4237/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 5.8940e-09 - mae: 3.2360e-05\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 91ms/step - loss: 5.8881e-09 - mae: 3.2347e-05 - val_loss: 3.6337e-06 - val_mae: 0.0015 - learning_rate: 1.6000e-06\n",
      "Epoch 12/50\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 88ms/step - loss: 5.9896e-09 - mae: 3.2356e-05 - val_loss: 3.6313e-06 - val_mae: 0.0015 - learning_rate: 1.0000e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 91ms/step - loss: 5.9476e-09 - mae: 3.2332e-05 - val_loss: 3.6340e-06 - val_mae: 0.0015 - learning_rate: 1.0000e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m4238/4238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 91ms/step - loss: 5.9148e-09 - mae: 3.2233e-05 - val_loss: 3.6299e-06 - val_mae: 0.0015 - learning_rate: 1.0000e-06\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\n",
      "Evaluating on test data...\n",
      "\u001b[1m4222/4222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step\n",
      "\n",
      "--- Test Metrics for N_AHEAD = 3 ---\n",
      "Mean RMSE across horizon: 1914.5631\n",
      "Mean MAPE across horizon: 9202.6203%\n",
      "RMSE per step: [1625.0389, 1826.0295, 2292.621]\n",
      "MAPE per step: [np.float64(8091.1998), np.float64(10040.8503), np.float64(9475.8107)]\n",
      "\n",
      "Saving artifacts...\n",
      "Model saved to: ./artifacts_unified/unified_lstm_nahead3.keras\n",
      "Scaler saved to: ./artifacts_unified/global_scaler.bin\n",
      "Scrip map saved to: ./artifacts_unified/scrip_to_id.json\n",
      "\n",
      "==================================================\n",
      "Training model for N_AHEAD = 7\n",
      "==================================================\n",
      "\n",
      "Building sequences...\n",
      "Train sequences: 1083401, Val sequences: 134855, Test sequences: 134919\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ ts_input            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">68,608</span> │ ts_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ scrip_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,744</span> │ scrip_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenation       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,504</span> │ concatenation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ ts_input            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m5\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m68,608\u001b[0m │ ts_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ scrip_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m49,408\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m21\u001b[0m)     │      \u001b[38;5;34m9,744\u001b[0m │ scrip_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenation       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m5,504\u001b[0m │ concatenation[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │        \u001b[38;5;34m455\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,719</span> (522.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m133,719\u001b[0m (522.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,719</span> (522.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,719\u001b[0m (522.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "Epoch 1/50\n",
      "\u001b[1m4233/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 90ms/step - loss: 3.2756e-07 - mae: 1.3653e-04 - val_loss: 6.5699e-06 - val_mae: 0.0018 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m4233/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 90ms/step - loss: 3.9347e-08 - mae: 9.2256e-05 - val_loss: 1.8426e-06 - val_mae: 7.7084e-04 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m4232/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3.4678e-08 - mae: 8.8392e-05\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m4233/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 89ms/step - loss: 3.3846e-08 - mae: 8.7110e-05 - val_loss: 1.1289e-07 - val_mae: 1.6821e-04 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m4233/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 89ms/step - loss: 1.8068e-08 - mae: 6.5475e-05 - val_loss: 1.7266e-07 - val_mae: 2.0402e-04 - learning_rate: 2.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m4232/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.6842e-08 - mae: 6.4815e-05\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m4233/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 89ms/step - loss: 1.6674e-08 - mae: 6.4146e-05 - val_loss: 1.9846e-07 - val_mae: 2.1003e-04 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m4233/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 89ms/step - loss: 1.5505e-08 - mae: 6.1548e-05 - val_loss: 1.7935e-07 - val_mae: 1.7264e-04 - learning_rate: 4.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m4232/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.5440e-08 - mae: 6.1548e-05\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m4233/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 89ms/step - loss: 1.5486e-08 - mae: 6.1532e-05 - val_loss: 1.7561e-07 - val_mae: 1.7181e-04 - learning_rate: 4.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m4233/4233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 89ms/step - loss: 1.5198e-08 - mae: 6.0868e-05 - val_loss: 1.7988e-07 - val_mae: 1.8130e-04 - learning_rate: 8.0000e-06\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Evaluating on test data...\n",
      "\u001b[1m4217/4217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step\n",
      "\n",
      "--- Test Metrics for N_AHEAD = 7 ---\n",
      "Mean RMSE across horizon: 345.0671\n",
      "Mean MAPE across horizon: 496.1478%\n",
      "RMSE per step: [359.8886, 319.5784, 364.4059, 347.6646, 314.9341, 338.609, 370.3888]\n",
      "MAPE per step: [np.float64(627.3707), np.float64(178.3347), np.float64(729.277), np.float64(480.6615), np.float64(391.8154), np.float64(289.9163), np.float64(775.6587)]\n",
      "\n",
      "Saving artifacts...\n",
      "Model saved to: ./artifacts_unified/unified_lstm_nahead7.keras\n",
      "Scaler saved to: ./artifacts_unified/global_scaler.bin\n",
      "Scrip map saved to: ./artifacts_unified/scrip_to_id.json\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def mape(y_true, y_pred, eps=1e-8):\n",
    "    return np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), eps))) * 100.0\n",
    "\n",
    "def inverse_transform_target(arr: np.ndarray, scaler: MinMaxScaler, n_features: int) -> np.ndarray:\n",
    "    \"\"\"Inverse transforms only the target column.\"\"\"\n",
    "    # Create a dummy array of the original feature shape, filled with zeros\n",
    "    dummy_array = np.zeros((len(arr), n_features))\n",
    "    # Place the scaled target data into the first column\n",
    "    dummy_array[:, 0] = arr.ravel()\n",
    "    # Inverse transform the entire dummy array\n",
    "    unscaled_array = scaler.inverse_transform(dummy_array)\n",
    "    # Return only the first column (the unscaled target)\n",
    "    return unscaled_array[:, 0]\n",
    "\n",
    "# --- Main Training Orchestration ---\n",
    "for n_ahead in HORIZONS:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training model for N_AHEAD = {n_ahead}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "\n",
    "    # 1. Build sequences for this horizon\n",
    "    print(\"Building sequences...\")\n",
    "    X_train, X_scrip_train, y_train = build_all_sequences(df_train, SCRIP_COLUMN, FEATURE_COLS, SEQ_LEN, n_ahead)\n",
    "    X_val, X_scrip_val, y_val = build_all_sequences(df_val, SCRIP_COLUMN, FEATURE_COLS, SEQ_LEN, n_ahead)\n",
    "    X_test, X_scrip_test, y_test = build_all_sequences(df_test, SCRIP_COLUMN, FEATURE_COLS, SEQ_LEN, n_ahead)\n",
    "    print(f\"Train sequences: {X_train.shape[0]}, Val sequences: {X_val.shape[0]}, Test sequences: {X_test.shape[0]}\")\n",
    "\n",
    "    # 2. Build the model\n",
    "    n_features = len(FEATURE_COLS)\n",
    "    model = build_unified_model(SEQ_LEN, n_features, n_scrips, n_ahead)\n",
    "    model.summary()\n",
    "\n",
    "    # 3. Train the model\n",
    "    print(\"\\nTraining model...\")\n",
    "    history = model.fit(\n",
    "        [X_train, X_scrip_train],\n",
    "        y_train,\n",
    "        epochs=MAX_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=([X_val, X_scrip_val], y_val),\n",
    "        callbacks=get_callbacks(),\n",
    "        shuffle=True, # Shuffle the combined dataset\n",
    "    )\n",
    "\n",
    "    # 4. Evaluate on the test set\n",
    "    print(\"\\nEvaluating on test data...\")\n",
    "    y_pred_scaled = model.predict([X_test, X_scrip_test])\n",
    "\n",
    "    # Inverse transform for metrics calculation (per step in horizon)\n",
    "    rmse_list, mape_list = [], []\n",
    "    for step in range(n_ahead):\n",
    "        y_true_step = inverse_transform_target(y_test[:, step], scaler, n_features)\n",
    "        y_pred_step = inverse_transform_target(y_pred_scaled[:, step], scaler, n_features)\n",
    "        rmse_list.append(rmse(y_true_step, y_pred_step))\n",
    "        mape_list.append(mape(y_true_step, y_pred_step))\n",
    "\n",
    "    print(f\"\\n--- Test Metrics for N_AHEAD = {n_ahead} ---\")\n",
    "    print(f\"Mean RMSE across horizon: {np.mean(rmse_list):.4f}\")\n",
    "    print(f\"Mean MAPE across horizon: {np.mean(mape_list):.4f}%\")\n",
    "    print(f\"RMSE per step: {[round(x, 4) for x in rmse_list]}\")\n",
    "    print(f\"MAPE per step: {[round(x, 4) for x in mape_list]}\")\n",
    "\n",
    "    # 5. Save artifacts\n",
    "    print(\"\\nSaving artifacts...\")\n",
    "    model_path = os.path.join(SAVE_DIR, f\"unified_lstm_nahead{n_ahead}.keras\")\n",
    "    scaler_path = os.path.join(SAVE_DIR, \"global_scaler.bin\")\n",
    "    scrip_map_path = os.path.join(SAVE_DIR, \"scrip_to_id.json\")\n",
    "\n",
    "    model.save(model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    with open(scrip_map_path, 'w') as f:\n",
    "        json.dump(scrip_to_id, f)\n",
    "\n",
    "    print(f\"Model saved to: {model_path}\")\n",
    "    print(f\"Scaler saved to: {scaler_path}\")\n",
    "    print(f\"Scrip map saved to: {scrip_map_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Example: How to Load and Predict for a Single Company\n",
    "\n",
    "This shows the new workflow for making a prediction:\n",
    "1.  Load the unified model, the **global** scaler, and the scrip-to-ID map.\n",
    "2.  Select a company and get its historical data.\n",
    "3.  Scale the data using the global scaler.\n",
    "4.  Get the company's integer ID from the map.\n",
    "5.  Feed both the scaled data and the ID into the model to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running prediction for ACI with 7-day model ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SAVE_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Running prediction for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEXAMPLE_SCRIP\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHORIZON_TO_PREDICT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-day model ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 1. Load artifacts\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m loaded_model = keras.models.load_model(os.path.join(\u001b[43mSAVE_DIR\u001b[49m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33munified_lstm_nahead\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHORIZON_TO_PREDICT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      9\u001b[39m loaded_scaler = joblib.load(os.path.join(SAVE_DIR, \u001b[33m\"\u001b[39m\u001b[33mglobal_scaler.bin\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(SAVE_DIR, \u001b[33m\"\u001b[39m\u001b[33mscrip_to_id.json\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'SAVE_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Example Prediction ---\n",
    "EXAMPLE_SCRIP = \"ACI\" # Choose a company from your dataset\n",
    "HORIZON_TO_PREDICT = 7 # Choose which trained model to use (1, 3, or 7)\n",
    "\n",
    "print(f\"--- Running prediction for {EXAMPLE_SCRIP} with {HORIZON_TO_PREDICT}-day model ---\")\n",
    "\n",
    "# 1. Load artifacts\n",
    "loaded_model = keras.models.load_model(os.path.join(SAVE_DIR, f\"unified_lstm_nahead{HORIZON_TO_PREDICT}.keras\"))\n",
    "loaded_scaler = joblib.load(os.path.join(SAVE_DIR, \"global_scaler.bin\"))\n",
    "with open(os.path.join(SAVE_DIR, \"scrip_to_id.json\"), 'r') as f:\n",
    "    loaded_scrip_map = json.load(f)\n",
    "\n",
    "# 2. Get the last SEQ_LEN days of data for the chosen scrip\n",
    "# In a real application, you would fetch this from your database or a new CSV\n",
    "scrip_df = df_all[df_all[SCRIP_COLUMN] == EXAMPLE_SCRIP].tail(SEQ_LEN)\n",
    "\n",
    "if len(scrip_df) < SEQ_LEN:\n",
    "    print(f\"Error: Not enough data for {EXAMPLE_SCRIP} to make a prediction (need {SEQ_LEN}, have {len(scrip_df)}).\")\n",
    "else:\n",
    "    # 3. Scale the features using the GLOBAL scaler\n",
    "    scaled_features = loaded_scaler.transform(scrip_df[FEATURE_COLS])\n",
    "\n",
    "    # 4. Get the scrip ID\n",
    "    scrip_id = loaded_scrip_map.get(EXAMPLE_SCRIP)\n",
    "    if scrip_id is None:\n",
    "        print(f\"Error: Scrip '{EXAMPLE_SCRIP}' not found in the training data.\")\n",
    "    else:\n",
    "        # 5. Reshape inputs for the model\n",
    "        X_pred = scaled_features.reshape(1, SEQ_LEN, len(FEATURE_COLS))\n",
    "        X_scrip_pred = np.array([scrip_id]).reshape(1, 1)\n",
    "\n",
    "        # 6. Predict\n",
    "        pred_scaled = loaded_model.predict([X_pred, X_scrip_pred]).ravel()\n",
    "\n",
    "        # 7. Inverse transform the prediction\n",
    "        # We need to do this for each step of the horizon\n",
    "        final_predictions = []\n",
    "        for pred_val in pred_scaled:\n",
    "            unscaled_pred = inverse_transform_target(np.array([pred_val]), loaded_scaler, len(FEATURE_COLS))\n",
    "            final_predictions.append(unscaled_pred[0])\n",
    "\n",
    "        print(f\"\\nPredicted closing prices for the next {HORIZON_TO_PREDICT} days:\")\n",
    "        for i, val in enumerate(final_predictions):\n",
    "            print(f\"  Day +{i+1}: {val:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
